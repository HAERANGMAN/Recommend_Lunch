{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import numpy \n",
    "import pandas as pd   \n",
    "import xlwt \n",
    "import random\n",
    "import os\n",
    "import urllib.request\n",
    "import urllib\n",
    "\n",
    "rjatordj= input('    1.검색어 입력: ')\n",
    "sec_name=rjatordj\n",
    "\n",
    "f_dir=input(r'C:\\Users\\201210961Desktop\\ ')\n",
    "\n",
    "query_txt='iherb'\n",
    "query_url='http://www.iherb.com'\n",
    "\n",
    "now = time.localtime()\n",
    "s = '%04d-%02d-%02d-%02d-%02d-%02d' % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec)\n",
    "\n",
    "os.makedirs(f_dir+s+'-'+query_txt+'-'+sec_name)\n",
    "os.chdir(f_dir+s+'-'+query_txt+'-'+sec_name)\n",
    "\n",
    "ff_dir=f_dir+s+'-'+query_txt+'-'+sec_name\n",
    "fx_name=f_dir+s+'-'+query_txt+'-'+sec_name+'\\\\'+s+'-'+query_txt+'-'+sec_name+'.xls'\n",
    "\n",
    "s_time = time.time( )\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_experimental_option(\"debuggerAddress\", \"127.0.0.1:9222\")\n",
    "chrome_driver = r\"C:\\Users\\201210961\\Desktop\\Coding\\Python Webscraping\\chromedriver_win32\\chromedriver.exe\" \n",
    "driver = webdriver.Chrome(chrome_driver, options=chrome_options)\n",
    "\n",
    "driver.get(query_url)\n",
    "time.sleep(0.5)\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"txtSearch\"]').send_keys(rjatordj)\n",
    "driver.find_element_by_xpath('//*[@id=\"txtSearch\"]').send_keys(Keys.ENTER)\n",
    "time.sleep(0.5)\n",
    "\n",
    "def scroll_down(driver):\n",
    "      \n",
    "      driver.execute_script(\"window.scrollBy(0,9300);\")\n",
    "      time.sleep(0.5)\n",
    "\n",
    "scroll_down(driver)\n",
    "\n",
    "# 비트맵 이미지 아이콘을 위한 대체 딕셔너리를 만듭니다\n",
    "bmp_map = dict.fromkeys(range(0x10000, sys.maxunicode + 1), 0xfffd)\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# 링크\n",
    "fldzm=[ ]\n",
    "# 이름 \n",
    "dlfma=[ ]\n",
    "# 가격\n",
    "rkrur=[ ]\n",
    "# 무게\n",
    "anrp=[ ]\n",
    "# 번호\n",
    "# no2=[]\n",
    "# no=sjaqj\n",
    "# 이미지1\n",
    "img1=[]\n",
    "# 이미지2\n",
    "img2=[]\n",
    "\n",
    "fldzmm=soup.find_all('a', class_='absolute-link product-link')\n",
    "\n",
    "for link in fldzmm:\n",
    "    fldzm.append(link.get('href'))\n",
    "\n",
    "# print(fldzm)\n",
    "\n",
    "# 1면따오기\n",
    "# for link in soup.find_all('a', class_='absolute-link product-link'):\n",
    "#     fldzm.append(link.get('href'))\n",
    "#     print(fldzm)\n",
    "    \n",
    "# 링크 각개전투\n",
    "for link in fldzm:\n",
    "    driver.get(link)\n",
    "    time.sleep(0.2)\n",
    "    html2 = driver.page_source\n",
    "    soup2 = BeautifulSoup(html2, 'html.parser')\n",
    "    \n",
    "    try :\n",
    "     dlfmaa=soup2.find('h1',id='name').get_text()\n",
    "    except AttributeError:\n",
    "     dlfmaa=''\n",
    "    else:\n",
    "     dlfma.append(dlfmaa)\n",
    "\n",
    "    try :\n",
    "     rkrurr=soup2.find('div',id='price').get_text().strip()\n",
    "    except AttributeError:\n",
    "     rkrurr=''\n",
    "    else:\n",
    "     rkrur.append(rkrurr)\n",
    "\n",
    "    try :\n",
    "     anrpp=soup2.find('span',class_='product-weight').get_text().strip()\n",
    "    except AttributeError:\n",
    "     anrpp=''\n",
    "    else:\n",
    "     anrp.append(anrpp)\n",
    "    \n",
    "    try :\n",
    "     img11=soup2.find('div', 'thumbnail-container').img['data-large-img']\n",
    "    except AttributeError:\n",
    "     img11=''\n",
    "    else:\n",
    "     img1.append(img11)\n",
    "    \n",
    "    try :\n",
    "     img22=soup2.select('div .thumbnail-container > img')[1]['data-large-img']\n",
    "    except IndexError:\n",
    "     img22=''\n",
    "    else:\n",
    "     img2.append(img22)\n",
    "  \n",
    "# img.append(soup.find('div', 'thumbnail-container').img['data-large-img'])\n",
    "# img.append(soup.select('div .thumbnail-container > img')[1]['data-large-img'])  \n",
    "        \n",
    "# print(fldzm)\n",
    "# print(dlfma)\n",
    "# print(rkrur)\n",
    "# print(anrp)\n",
    "\n",
    "#Step 5. 검색 결과를 다양한 형태로 저장하기\n",
    "              \n",
    "iherb = pd.DataFrame()\n",
    "iherb['링크']=fldzm\n",
    "iherb['이름']=pd.Series(dlfma)\n",
    "iherb['가격']=pd.Series(rkrur)\n",
    "iherb['무게']=pd.Series(anrp)\n",
    "iherb['이미지1']=pd.Series(img1)\n",
    "iherb['이미지2']=pd.Series(img2)\n",
    "\n",
    "# 엑셀 형태로 저장하기\n",
    "orig_stdout = sys.stdout\n",
    "iherb.to_excel(fx_name ,index=True)\n",
    "\n",
    "e_time = time.time( )\n",
    "t_time = e_time - s_time\n",
    "\n",
    "# Step 6. 요약 정보를 출력하기\n",
    "print(\"\\n\")\n",
    "print(\"=\" *50)\n",
    "print(\"총 소요시간은 %s 초입니다\" %t_time)\n",
    "print('%s를 확인하세요! 쎆쓰!' %f_dir)\n",
    "print(\"=\" *50)\n",
    "\n",
    "# sys.stdout = orig_stdout\n",
    "# f.close( )\n",
    "\n",
    "# print(\"\\n\") \n",
    "# print(\"=\" *80)\n",
    "# # print(\"1.요청된 총 %s 건의 리뷰 중에서 실제 크롤링 된 리뷰수는 %s 건입니다\" %(cnt,count))\n",
    "# print(\"2.총 소요시간은 %s 초 입니다\" %round(t_time,1))\n",
    "# print(\"=\" *80)    \n",
    "\n",
    "# # driver.switch_to_window(driver.window_handles[1]) \n",
    "# driver.get_window_position(driver.window_handles[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_element_by_id\n",
    "# find_element_by_name\n",
    "# find_element_by_xpath\n",
    "# find_element_by_link_text\n",
    "# find_element_by_partial_link_text\n",
    "# find_element_by_tag_name\n",
    "# find_element_by_class_name\n",
    "# find_element_by_css_selector\n",
    "# ----------------(단수//복수)------------------\n",
    "# find_elements_by_name\n",
    "# find_elements_by_xpath\n",
    "# find_elements_by_link_text\n",
    "# find_elements_by_partial_link_text\n",
    "# find_elements_by_tag_name\n",
    "# find_elements_by_class_name\n",
    "# find_elements_by_css_selector\n",
    "# ---------------------------------------------------------\n",
    "# # 가격을 가져올때(첫 번째 꺼 하나만)\n",
    "# soup.select('p > span.price')[0].text   \n",
    "# ※ [0] 을 통해 첫 번째에 나오는 값이라고 한정 시켜줌. 중요!!!!\n",
    "\n",
    "# # 가격을 가져올때(복수)\n",
    "# prices = soup.select('p > span.price')\n",
    "# for price in prices:        # 복수의 가격 정보들에서 하나씩 꺼내어\n",
    "#     print(price.text)       # 텍스트만 화면에 출력한다\n",
    "\n",
    "# 속성를 가져올때(첫 번째 꺼 하나만)\n",
    "# select('a')[0]['href']\n",
    "# ---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
